{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd21bed2-5659-4c8b-89ba-7b2a7ac62db4",
   "metadata": {},
   "source": [
    "### Question 1. Explain the properties of the F-distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72f1f27-8dce-4580-a454-bbb50b3c94cb",
   "metadata": {},
   "source": [
    "#### Answer.\n",
    "The F-distribution, named after Sir Ronald Fisher, is a continuous probability distribution used in statistical inference,\n",
    "particularly in hypothesis testing and regression analysis. Here are its key properties:\n",
    "\n",
    "Key Properties\n",
    "\n",
    "1. Non-symmetric distribution: The F-distribution is skewed to the right, with a longer tail on the right side.\n",
    "2. Positive values : he F-distribution can only have positive values range from 0 to infinity.\n",
    "3. Two degrees of freedom: The F-distribution is characterized by two degrees of freedom: numerator degrees of freedom (df1) and \n",
    "   denominator degrees of freedom (df2).\n",
    "4. Approximates the normal distribution: As the degrees of freedom for the numerator and denominator increase, the F-distribution\n",
    "   becomes more similar to a normal distribution.\n",
    "5. F-statistic: The F-statistic is greater than or equal to zero.\n",
    "6. Shape parameter: The shape of the F-distribution depends on the two degrees of freedom.\n",
    "7. Mean and median: The mean of the F-distribution is generally not equal to the median because of the skewness.\n",
    "8. Mean and variance: The mean (Œº) and variance (œÉ¬≤) of the F-distribution are:\n",
    "- Œº = df2 / (df2 - 2) for df2 > 2\n",
    "- œÉ¬≤ = 2 * df2¬≤ * (df1 + df2 - 2) / (df1 * (df2 - 2)¬≤ * (df2 - 4)) for df2 > 4\n",
    "9. Uses: The F-distribution is used in statistical inference, including ANOVA, regression analysis, and the F-test. It can also be \n",
    "   used to compare two variances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ae3890-b414-4984-8d7b-20f1f229205e",
   "metadata": {},
   "source": [
    "### Question 2. In which types of statistical tests is the F-distribution used, and why is it appropriate for these tests?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9dc4be6-8b3c-45aa-aae1-9db3c8dee613",
   "metadata": {},
   "source": [
    "#### Answer. \n",
    "The F-distribution is used in various statistical tests, primarily for:\n",
    "\n",
    "Tests for Comparing Variances\n",
    "\n",
    "1. F-test for Equality of Variances: Compares variances between two populations.\n",
    "2. Analysis of Variance (ANOVA): Compares means among multiple groups.\n",
    "3. Analysis of Covariance (ANCOVA): Compares means while controlling for covariates.\n",
    "\n",
    "Regression Analysis\n",
    "\n",
    "1. F-test for Regression Coefficients: Tests significance of regression coefficients.\n",
    "2. F-test for Overall Regression Model: Tests overall significance of the regression model.\n",
    "\n",
    "Other Tests\n",
    "\n",
    "1. Test for Homogeneity of Variances: Assesses equal variances across multiple groups.\n",
    "2. Test for Equality of Means: Compares means between two or more groups.\n",
    "\n",
    "Why F-distribution is appropriate:\n",
    "\n",
    "1. Ratio of Variances: F-distribution models the ratio of two variances, making it suitable for comparing variances.\n",
    "2. Scaling: F-distribution accounts for differences in scale between variances.\n",
    "3. Degrees of Freedom: F-distribution incorporates degrees of freedom, reflecting sample sizes.\n",
    "4. Robustness: F-distribution is robust against non-normality and outliers.\n",
    "\n",
    "By using the F-distribution in these tests, researchers and analysts can make informed decisions about the significance of their\n",
    "findings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b538f520-d5b6-48fa-b3f6-eeee954090a9",
   "metadata": {},
   "source": [
    "### Question 3. What are the key assumptions required for conducting an F-test to compare the variances of two populations?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba0ed9c-5efa-4f69-91f5-2e48c5d78b67",
   "metadata": {},
   "source": [
    "#### Answer.\n",
    "Conducting an F-test to compare variances requires the following key assumptions:\n",
    "\n",
    "Assumptions:\n",
    "\n",
    "1. Normality: Both populations should follow normal distributions.\n",
    "\n",
    "2. Independence: Observations should be independent within and between samples.\n",
    "\n",
    "3. Homoscedasticity (Equal Variances): The test assumes equal variances, but this is what's being tested.\n",
    "\n",
    "4. Random Sampling: Samples should be randomly selected from their respective populations.\n",
    "\n",
    "5. No Outliers: No significant outliers in either sample.\n",
    "\n",
    "Additional Considerations:\n",
    "\n",
    "1. Sample Size: Preferably, samples should have equal sizes.\n",
    "\n",
    "2. Population Parameters: The test assumes the populations have the same shape and location.\n",
    "\n",
    "Consequences of Violating Assumptions:\n",
    "\n",
    "1. Reduced Power: Violations reduce the test's ability to detect significant differences.\n",
    "\n",
    "2. Increased Type I Error: Incorrect rejections of the null hypothesis.\n",
    "\n",
    "Alternatives when Assumptions are Violated:\n",
    "\n",
    "1. Transform Data: Stabilize variance or normalize data.\n",
    "\n",
    "2. Non-Parametric Tests: Use tests like Levene's or Brown-Forsythe.\n",
    "\n",
    "Common Statistical Software:\n",
    "\n",
    "1. R: var.test()\n",
    "\n",
    "2. Python: scipy.stats.f_oneway()\n",
    "\n",
    "3. Excel: F.TEST()\n",
    "\n",
    "By ensuring these assumptions are met, you can confidently conduct an F-test to compare variances between two populations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b1e951-77f6-4f04-8539-4fec3fa9c4bc",
   "metadata": {},
   "source": [
    "### Question 4. What is the purpose of ANOVA, and how does it differ from a t-test? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b6f138-871c-426f-b58c-b9a8f6a4754b",
   "metadata": {},
   "source": [
    "#### Answer. \n",
    "Purpose of ANOVA and its Difference from a t-test:\n",
    "\n",
    "The purpose of ANOVA (Analysis of Variance) is to determine whether there are significant differences among the means of three or more groups. It helps assess whether variations in the dependent variable are due to differences between group means or random variation within groups. ANOVA is commonly used in experiments where multiple groups or factors are involved.\n",
    "\n",
    "Key differences between ANOVA and a t-test:\n",
    "\n",
    "1.Number of Groups:\n",
    "\n",
    "A t-test is typically used to compare the means of two groups.\n",
    "ANOVA is used to compare the means of three or more groups.\n",
    "\n",
    "2.Type of Analysis:\n",
    "\n",
    "The t-test evaluates the difference between two means directly.\n",
    "ANOVA assesses the variance within groups and between groups to infer if at least one group mean is significantly different from the others.\n",
    "\n",
    "3.Extension for Multiple Comparisons:\n",
    "\n",
    "Performing multiple t-tests increases the risk of a Type I error (false positive).\n",
    "ANOVA controls this risk by providing a single test to analyze all groups simultaneously.\n",
    "\n",
    "4.Output:\n",
    "\n",
    "A t-test provides a p-value for a direct comparison.\n",
    "ANOVA provides an F-statistic and a corresponding p-value, indicating whether differences exist among group means, but additional post-hoc tests are needed to pinpoint which groups differ.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318c2063-6685-4310-9ebd-97470ee09e03",
   "metadata": {},
   "source": [
    "### Question 5. Explain when and why you would use a one-way ANOVA instead of multiple t-tests when comparing more than two groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ecb7df-775c-43da-92a6-6a16999e3f8b",
   "metadata": {},
   "source": [
    "#### Answer. \n",
    "When comparing more than two groups, you would use a one-way ANOVA instead of multiple t-tests for the following reasons:\n",
    "\n",
    "When to use a one-way ANOVA\n",
    "\n",
    "1. Comparing more than two groups: A one-way ANOVA is appropriate when you want to determine whether there are statistically \n",
    "   significant differences in the means of three or more groups.\n",
    "2. Independent samples: The groups being compared should consist of independent samples (e.g.,different participants in each group).\n",
    "3. One independent variable: A one-way ANOVA is used when there is a single independent variable (factor) with multiple levels \n",
    "(e.g., different treatment groups).\n",
    "\n",
    "Why use a one-way ANOVA instead of multiple t-tests\n",
    "\n",
    "1. Avoiding Type I error inflation: Performing multiple t-tests increases the likelihood of committing a Type I error \n",
    "(false positive). For example, if you conduct three t-tests with a significance level of 0.05 for each, the cumulative probability \n",
    "of at least one false positive result becomes greater than 5%. A one-way ANOVA controls for this error by testing all group means \n",
    "simultaneously under a single analysis.\n",
    "2. Efficiency: A one-way ANOVA is a more streamlined approach because it evaluates all group differences in a single test rather \n",
    "than requiring multiple pairwise comparisons.\n",
    "3. Interpretability: A one-way ANOVA provides an overall test of whether any group mean differs from the others, making it a more \n",
    "straightforward initial analysis. If significant differences are detected, post-hoc tests can identify which groups are different.\n",
    "    \n",
    "Example\n",
    "    \n",
    "If you want to compare the exam scores of students from three different teaching methods (Method A, Method B, and Method C), a \n",
    "one-way ANOVA would test whether the mean scores differ among the three groups without increasing the risk of Type I error. Using\n",
    "multiple t-tests (e.g., A vs. B, A vs. C, B vs. C) would inflate the error rate and lead to less reliable results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2f11f2-9e4c-44de-b046-fe9058050c10",
   "metadata": {},
   "source": [
    "### Question 6. Explain how variance is partitioned in ANOVA into between-group variance and within-group variance. How does this partitioning contribute to the calculation of the F-statistic?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044064b7-017e-4efd-b36e-eee45196b456",
   "metadata": {},
   "source": [
    "#### Answer.\n",
    "Partitioning Variance in ANOVA\n",
    "\n",
    "In Analysis of Variance (ANOVA), the total variance in the data is divided into two components: between-group variance and \n",
    "within-group variance. This partitioning helps identify whether there are significant differences between the means of the groups\n",
    "being compared.\n",
    "\n",
    "1. Between-Group Variance (SSB):\n",
    "   This represents the variation due to differences between the group means. It measures how far the group means are from the\n",
    "   overall mean of the data. A larger between-group variance indicates greater differences among the group means.\n",
    "   \n",
    "    Mathematically, it is calculated as:\n",
    "                             \n",
    "####                              SSB = ‚àë[i=1 to k] ni (XÀâi - XÀâoverall)¬≤\n",
    "\n",
    "Where:\n",
    "\n",
    "- SSB = Between-Group Sum of Squares\n",
    "- ni = Sample size of group i\n",
    "- XÀâi = Mean of group i\n",
    "- XÀâoverall = Overall mean (grand mean)\n",
    "- k = Number of groups\n",
    "\n",
    "2.Within-Group Variance (SSW):\n",
    "  This represents the variation within each group and measures how data points within a group deviate from their group mean. This\n",
    "  captures the natural variability within each group.\n",
    "\n",
    "Mathematically, it is calculated as:\n",
    "                        \n",
    "####                          SSW = ‚àë[i=1 to k] ‚àë[j=1 to ni] (Xij - XÀâi)¬≤\n",
    "\n",
    "Where:\n",
    "\n",
    "- SSW = Within-Group Sum of Squares\n",
    "- Xij = jth observation in group i\n",
    "- XÀâi = Mean of group i\n",
    "- ni = Sample size of group i\n",
    "- k = Number of groups\n",
    "\n",
    "\n",
    "Total Variance (SST):\n",
    "The total variance in the data is the sum of the between-group and within-group variance:\n",
    "\n",
    "####                                         ùëÜùëÜùëá=ùëÜùëÜùêµ+ùëÜùëÜùëä\n",
    "\n",
    "Role in the F-Statistic Calculation\n",
    "\n",
    "The F-statistic in ANOVA is a ratio of variances: the variance due to group differences (between-group) to the variance within \n",
    "groups (within-group). This is expressed as:\n",
    "\n",
    "####                            ùêπ=Mean¬†Square¬†Between¬†(MSB)/Mean¬†Square¬†Within¬†(MSW)\n",
    "\n",
    "*MSB (Mean Square Between) is the between-group variance normalized by its degrees of freedom:\n",
    "                                   \n",
    "####                                   MSB=SSB/k‚àí1\n",
    "\n",
    "*MSW (Mean Square Within) is the within-group variance normalized by its degrees of freedom:\n",
    "                                    \n",
    "####                                   MSW= SSW/N‚àík\n",
    "\n",
    "where N is the total number of observations.\n",
    "A larger F-value suggests that the variation between groups is greater than the variation within groups, which may indicate that the\n",
    "group means are significantly different. The significance of the F-statistic is determined using an F-distribution and a specified \n",
    "significance level.\n",
    "\n",
    "This framework allows researchers to evaluate whether observed differences among group means are statistically significant or likely\n",
    "due to random variation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec2fc02-ae54-4fd6-95d4-f27b940927e7",
   "metadata": {},
   "source": [
    "### Question 7. Compare the classical (frequentist) approach to ANOVA with the Bayesian approach. What are the key differences in terms of how they handle uncertainty, parameter estimation, and hypothesis testing?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ab5d14-dd75-4220-843b-f05a804cb473",
   "metadata": {},
   "source": [
    "#### Answer. \n",
    "#### 1. Uncertainty\n",
    "\n",
    "Frequentist Approach:\n",
    "\n",
    "Uncertainty is handled using probabilities that are based on the long-run frequency of outcomes.\n",
    "The analysis relies on sampling distributions to quantify uncertainty. For example, p-values and confidence intervals are derived \n",
    "from the assumption of repeated sampling.\n",
    "\n",
    "Bayesian Approach:\n",
    "\n",
    "Uncertainty is expressed through probability distributions over parameters and hypotheses. These distributions are updated as data \n",
    "is observed.\n",
    "Prior beliefs (priors) about parameters are combined with the observed data to produce posterior distributions, which directly \n",
    "describe the uncertainty in parameter estimates.\n",
    "\n",
    "#### 2. Parameter Estimation\n",
    "\n",
    "Frequentist Approach:\n",
    "\n",
    "Parameters are considered fixed but unknown quantities.\n",
    "Estimates are obtained through methods like maximum likelihood estimation (MLE). For ANOVA, it calculates variance components \n",
    "(e.g., between-group and within-group variance) \n",
    "without directly estimating distributions for the parameters.\n",
    "Confidence intervals are used to provide a range of plausible values for parameters.\n",
    "\n",
    "Bayesian Approach:\n",
    "\n",
    "Parameters are treated as random variables with probability distributions.\n",
    "Posterior distributions for parameters are calculated using Bayes' theorem, combining prior distributions with the likelihood of the\n",
    "observed data.\n",
    "Instead of point estimates, Bayesian methods provide a full distribution of parameter estimates, allowing more nuanced inferences.\n",
    "\n",
    "#### 3. Hypothesis Testing\n",
    "\n",
    "Frequentist Approach:\n",
    "\n",
    "Hypothesis testing relies on p-values and the rejection of a null hypothesis (H0) at a specified significance level (ùõº).\n",
    "ANOVA tests whether the group means are equal (ùêª0:ùúá1=ùúá2=‚ãØ=ùúáùëò) by comparing the F-statistic to a critical value from the \n",
    "F-distribution.\n",
    "The decision is binary: reject or fail to reject ùêª0.\n",
    "\n",
    "Bayesian Approach:\n",
    "\n",
    "Hypotheses are compared using posterior probabilities or Bayes factors, which quantify the relative evidence for one hypothesis over\n",
    "another.\n",
    "The Bayesian approach is more flexible, as it doesn‚Äôt require a binary decision. Instead, it evaluates the strength of evidence for \n",
    "competing hypotheses.\n",
    "For example, a Bayes factor greater than 10 might indicate strong evidence in favor of the alternative hypothesis.\n",
    "\n",
    "#### 4. Role of Priors\n",
    "\n",
    "Frequentist Approach:\n",
    "                                      \n",
    "Does not involve prior information. Results depend solely on the observed data and the assumptions of the model.\n",
    "Bayesian Approach:\n",
    "Requires the specification of prior distributions for model parameters. Priors can incorporate existing knowledge or be chosen as \n",
    "non-informative to let the data dominate the posterior inference.\n",
    "The choice of priors can strongly influence results, particularly with small sample sizes.\n",
    "                                      \n",
    "#### 5. Interpretation of Results\n",
    "\n",
    "Frequentist Approach:\n",
    "\n",
    "Results are interpreted in terms of probabilities based on hypothetical repeated sampling. For example, a 95% confidence interval \n",
    "means that 95% of intervals calculated from repeated samples would contain the true parameter value.\n",
    "P-values are interpreted as the probability of observing data as extreme as the observed data, assuming ùêª0 is true.\n",
    "\n",
    "Bayesian Approach:\n",
    "\n",
    "Results are interpreted directly as probabilities about the parameters or hypotheses. For example, the posterior distribution can be\n",
    "used to state that there is a 95% probability that a parameter lies within a specific range.\n",
    "Bayesian results provide a more intuitive understanding of uncertainty and evidence.\n",
    "\n",
    "Both approaches have their strengths: the frequentist method is simpler and more widely used, while the Bayesian approach offers\n",
    "greater flexibility and a more intuitive framework for uncertainty and decision-making.                                     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13699573-5bfd-49cc-95a3-c647878884db",
   "metadata": {},
   "source": [
    "### Question 8. You have two sets of data representing the incomes of two different professions1\n",
    "### V Profession A: [48, 52, 55, 60, 62'\n",
    "### V Profession B: [45, 50, 55, 52, 47] Perform an F-test to determine if the variances of the two professions'\n",
    "### incomes are equal. What are your conclusions based on the F-test?\n",
    "### Task: Use Python to calculate the F-statistic and p-value for the given data.\n",
    "### Objective: Gain experience in performing F-tests and interpreting the results in terms of variance comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa1c2110-2623-465e-8df3-6525cf9af0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic for ANOVA: 3.232989690721649\n",
      "p-value for ANOVA: 0.10987970118946545\n",
      "F-statistic for Variance Comparison: 0.7368421052631583\n",
      "p-value for Variance Comparison: 0.4156507222081854\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Data for Profession A and Profession B\n",
    "profession_A = [48, 52, 55, 60, 62]\n",
    "profession_B = [45, 50, 55, 52, 47]\n",
    "\n",
    "# Calculate the F-statistic and p-value\n",
    "f_statistic, p_value = stats.f_oneway(profession_A, profession_B)\n",
    "\n",
    "# Alternatively, to directly compare variances\n",
    "f_statistic_variance, p_value_variance = stats.levene(profession_A, profession_B)\n",
    "\n",
    "print(\"F-statistic for ANOVA:\", f_statistic)\n",
    "print(\"p-value for ANOVA:\", p_value)\n",
    "\n",
    "print(\"F-statistic for Variance Comparison:\", f_statistic_variance)\n",
    "print(\"p-value for Variance Comparison:\", p_value_variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2e9a88-dd97-4941-9f9e-4a35786caa04",
   "metadata": {},
   "source": [
    "### Question 9' Conduct a one-way ANOVA to test whether there are any statistically significant differences in\n",
    "### average heights between three different regions with the following data1\n",
    "### V Region A: [160, 162, 165, 158, 164'\n",
    "### V Region B: [172, 175, 170, 168, 174'\n",
    "### V Region C: [180, 182, 179, 185, 183'\n",
    "### V Task: Write Python code to perform the one-way ANOVA and interpret the results\f",
    "\n",
    "### V Objective: Learn how to perform one-way ANOVA using Python and interpret F-statistic and p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49e316fd-9312-4bbe-9728-d08cc9b868fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 67.87330316742101\n",
      "p-value: 2.8706641879370266e-07\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Data for Region A, Region B, and Region C\n",
    "region_A = [160, 162, 165, 158, 164]\n",
    "region_B = [172, 175, 170, 168, 174]\n",
    "region_C = [180, 182, 179, 185, 183]\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(region_A, region_B, region_C)\n",
    "\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
